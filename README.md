# ğŸ§  Conversational RAG Chatbot with LangChain, FAISS, and Gradio

A context-aware chatbot using Retrieval-Augmented Generation (RAG), built with:

- ğŸ”— **LangChain** for orchestration
- ğŸ§  **FAISS** for fast vector search
- ğŸ—£ï¸ **OpenAI's GPT models** for intelligent responses
- ğŸ›ï¸ **Gradio** for the interactive web UI

---

[![Hugging Face Spaces](https://img.shields.io/badge/ğŸ¤—%20HuggingFace-Demo-blueviolet?logo=huggingface&logoColor=white)](https://huggingface.co/spaces/Nishthaaa/langchain_openai_rag_chatbot)

### ğŸ”— [Live Demo on Hugging Face Spaces](https://huggingface.co/spaces/Nishthaaa/langchain_openai_rag_chatbot)

---

## ğŸ“ Features

- âœ… Loads `.txt` documents from a local folder
- âœ… Builds or loads a FAISS index for fast semantic search
- âœ… Uses `SentenceTransformer` for embeddings
- âœ… GPT-based Q&A using only retrieved context
- âœ… Follows conversation history for follow-up questions
- âœ… Web UI built with Gradio and hosted on Hugging Face

---

## ğŸš€ Getting Started (Local Setup)

### 1. Clone the Repository

```bash
git clone https://github.com/your-username/conversational-rag-chatbot.git
cd conversational-rag-chatbot
````

### 2. Create and Activate a Virtual Environment

```bash
python -m venv venv
source venv/bin/activate      # On Windows: venv\Scripts\activate
```

### 3. Install Required Packages

```bash
pip install -r requirements.txt
```

### 4. Create a `.env` File

```env
FOLDER_PATH=ancient_greece
INDEX_PATH=faiss_index
EMBEDDING_MODEL_NAME=all-MiniLM-L6-v2
LLM_MODEL_NAME=gpt-4o-mini
```

Put your `.txt` files in the `ancient_greece/` directory.

### 5. Run the Application

```bash
python app.py
```

This will launch a Gradio interface at `http://localhost:7860`.

---

## ğŸ“‚ Folder Structure

```
â”œâ”€â”€ app.py                     # gradio app script
â”œâ”€â”€ conversational_rag_chain.py  # chatbot script
â”œâ”€â”€ ancient_greece/        # Text documents go here
â”œâ”€â”€ evaluation/        # evaluation script
   â”œâ”€â”€evaluation_questions.json
   â”œâ”€â”€evaluation_test.py
      â”œâ”€â”€result/chatbot_evaluation_results.csv
â”œâ”€â”€ .env                       # Environment variables
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
â””â”€â”€ notebook.ipynb
```

---

## ğŸ§  How It Works

1. **Ingestion**: `.txt` files are loaded and cleaned.
2. **Embedding**: Text is embedded using `SentenceTransformer`.
3. **Indexing**: Vectors are stored in a FAISS index for similarity search.
4. **Conversation Flow**:

   * Follow-up questions are rewritten into standalone ones.
   * Contextually relevant documents are retrieved.
   * GPT responds using only the retrieved content.
5. **Session History**: Tracked using LangChainâ€™s message history interface.

---

## ğŸ’¬ Example Interactions

> **User**: Who was Socrates?
> **Bot**: Socrates was a classical Greek philosopher known for...

> **User**: What were his beliefs about virtue?
> **Bot**: Socrates believed that virtue is a kind of knowledge...

> **User**: And what did Plato say about that?
> **Bot**: Plato expanded on Socratesâ€™ ideas, stating that...

---

## â˜ï¸ Hosted Version

You can try this app live on Hugging Face Spaces:

ğŸ‘‰ [**Click here for the demo**](https://huggingface.co/spaces/Nishthaaa/langchain_openai_rag_chatbot)

---

## ğŸ›¡ï¸ Security Note

> âš ï¸ FAISS index is loaded with `allow_dangerous_deserialization=True`.
> Only load trusted indexes to avoid potential security risks.

---

## ğŸ› ï¸ Deployment on Hugging Face

To deploy your own version:

1. Push your app code and `.env` to secret section of Hugging Face under space setiing.
2. Ensure `app.py` is the entry point.
3. Add `requirements.txt` with all dependencies.

---

## ğŸ“Š Evaluation

The chatbotâ€™s answers are rigorously evaluated using both classic NLP metrics and LLM-based criteria:

### 1. **Automatic Metrics**
- **Cosine Similarity (TF-IDF):** Measures textual similarity between the chatbotâ€™s answer and the expected answer.
- **BLEU:** Evaluates n-gram overlap for fluency and relevance.
- **ROUGE:** Assesses recall and precision of overlapping phrases.
- **METEOR:** Considers synonymy and word order.
- **BERTScore:** Uses contextual embeddings for semantic similarity.

### 2. **LLM-Based Evaluation**
- **Faithfulness:** Does the answer accurately reflect the information present in the provided context?
- **Context Faithfulness:** Is the answer faithful to the retrieved context and does not introduce information not present in the context?
- **Relevance:** Judges if the answer is relevant to the question.
- **Truthfulness:** Assesses factual correctness using a language model.

### **How Evaluation Works**
- A set of evaluation questions and expected answers are loaded from a JSON file (`evaluation/evaluation_questions.json`).
- For each question, the chatbot generates an answer and retrieves supporting context.
- The answer is compared to the expected answer using the above metrics.
- Results are saved to a CSV file for analysis (`evaluation/result/chatbot_evaluation_results.csv`).

### **Run the Evaluation**
To run the evaluation, use:
```bash
python evaluation/evaluation_test.py
```
The results will be printed and saved for further analysis.



---

## ğŸ“ˆ Future Improvements

* ğŸ”„ Support for PDFs, DOCX, or Markdown files
* ğŸ§¾ Downloadable chat history
* ğŸ—‚ï¸ File upload and auto-indexing
* ğŸ” User session tracking via cookies or tokens
* ğŸ¨ UI customization and themes

---

## ğŸ™Œ Acknowledgements

* [LangChain](https://www.langchain.com/)
* [OpenAI](https://platform.openai.com/)
* [Gradio](https://gradio.app/)
* [FAISS](https://github.com/facebookresearch/faiss)
* [SentenceTransformers](https://www.sbert.net/)